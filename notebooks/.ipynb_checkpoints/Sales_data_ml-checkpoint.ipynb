{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d025b1b5-322e-40da-a12e-a7d4e8887144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecfb0bdc-8982-4dcd-b012-2e094e45c440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order_ID</th>\n",
       "      <th>Order_Date</th>\n",
       "      <th>Ship_Date</th>\n",
       "      <th>Ship_Mode</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Customer_Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>...</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday_1to7</th>\n",
       "      <th>quarter</th>\n",
       "      <th>weekday_name</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>profit_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Row ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>2016-08-11</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>2016-08-11</td>\n",
       "      <td>2016-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA-2016-138688</td>\n",
       "      <td>2016-12-06</td>\n",
       "      <td>2016-06-16</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>2015-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "      <td>2015</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Order_ID  Order_Date   Ship_Date       Ship_Mode Customer_ID  \\\n",
       "Row ID                                                                       \n",
       "1       CA-2016-152156  2016-08-11  2016-11-11    Second Class    CG-12520   \n",
       "2       CA-2016-152156  2016-08-11  2016-11-11    Second Class    CG-12520   \n",
       "3       CA-2016-138688  2016-12-06  2016-06-16    Second Class    DV-13045   \n",
       "4       US-2015-108966  2015-11-10  2015-10-18  Standard Class    SO-20335   \n",
       "5       US-2015-108966  2015-11-10  2015-10-18  Standard Class    SO-20335   \n",
       "\n",
       "          Customer_Name    Segment        Country             City  \\\n",
       "Row ID                                                               \n",
       "1           Claire Gute   Consumer  United States        Henderson   \n",
       "2           Claire Gute   Consumer  United States        Henderson   \n",
       "3       Darrin Van Huff  Corporate  United States      Los Angeles   \n",
       "4        Sean O'Donnell   Consumer  United States  Fort Lauderdale   \n",
       "5        Sean O'Donnell   Consumer  United States  Fort Lauderdale   \n",
       "\n",
       "             State  ...  Discount    Profit  year month day weekday_1to7  \\\n",
       "Row ID              ...                                                    \n",
       "1         Kentucky  ...      0.00   41.9136  2016     8  11            4   \n",
       "2         Kentucky  ...      0.00  219.5820  2016     8  11            4   \n",
       "3       California  ...      0.00    6.8714  2016    12   6            2   \n",
       "4          Florida  ...      0.45 -383.0310  2015    11  10            2   \n",
       "5          Florida  ...      0.20    2.5164  2015    11  10            2   \n",
       "\n",
       "        quarter  weekday_name  is_weekend  profit_ratio  \n",
       "Row ID                                                   \n",
       "1             3      Thursday           0         0.160  \n",
       "2             3      Thursday           0         0.300  \n",
       "3             4       Tuesday           0         0.470  \n",
       "4             4       Tuesday           0        -0.400  \n",
       "5             4       Tuesday           0         0.112  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"D:\\sales-forecast-ml-project\\data\\processed\\sales_processed_data.csv\", index_col = 'Row ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "366e73f3-c41b-4aa1-8e6b-c487335483a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after 5% outlier removal: (9494, 28)\n",
      "RandomForest completed.\n",
      "GradientBoosting completed.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 993\n",
      "[LightGBM] [Info] Number of data points in the train set: 5063, number of used features: 135\n",
      "[LightGBM] [Info] Start training from score 169.890173\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 5063, number of used features: 134\n",
      "[LightGBM] [Info] Start training from score 162.250185\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 996\n",
      "[LightGBM] [Info] Number of data points in the train set: 5064, number of used features: 137\n",
      "[LightGBM] [Info] Start training from score 163.684256\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1232\n",
      "[LightGBM] [Info] Number of data points in the train set: 7595, number of used features: 252\n",
      "[LightGBM] [Info] Start training from score 165.274766\n",
      "LightGBM completed.\n",
      "XGBoost completed.\n",
      "\n",
      "Model Comparison:\n",
      "              Model  CV_R2_Mean  CV_R2_Std   Test_R2       RMSE\n",
      "2          LightGBM    0.961016   0.006725  0.963893  48.420162\n",
      "0      RandomForest    0.953383   0.002780  0.958277  52.049997\n",
      "3           XGBoost    0.950685   0.001329  0.943730  60.446594\n",
      "1  GradientBoosting    0.896216   0.008372  0.891373  83.985223\n",
      "\n",
      "==============================\n",
      "ðŸ† BEST MODEL\n",
      "==============================\n",
      "Model Name  : LightGBM\n",
      "CV R2 Mean  : 0.9610\n",
      "Test R2     : 0.9639\n",
      "RMSE        : 48.4202\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 1ï¸âƒ£ 5% OUTLIER REMOVAL\n",
    "# =====================================\n",
    "\n",
    "lower = df[\"Sales\"].quantile(0.025)\n",
    "upper = df[\"Sales\"].quantile(0.975)\n",
    "\n",
    "df = df[(df[\"Sales\"] >= lower) & (df[\"Sales\"] <= upper)]\n",
    "\n",
    "print(\"Dataset shape after 5% outlier removal:\", df.shape)\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 2ï¸âƒ£ Feature / Target Split\n",
    "# =====================================\n",
    "\n",
    "X = df.drop(\"Sales\", axis=1)\n",
    "y = df[\"Sales\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 3ï¸âƒ£ Column Detection\n",
    "# =====================================\n",
    "\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_features = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 4ï¸âƒ£ Preprocessing\n",
    "# =====================================\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numeric_features),\n",
    "    (\"cat\", categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 5ï¸âƒ£ Balanced Models (n_jobs=1)\n",
    "# =====================================\n",
    "\n",
    "models = {\n",
    "\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=12,\n",
    "        min_samples_split=5,\n",
    "        random_state=42,\n",
    "        n_jobs=1\n",
    "    ),\n",
    "\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    ),\n",
    "\n",
    "    \"LightGBM\": LGBMRegressor(\n",
    "        n_estimators=120,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=1\n",
    "    ),\n",
    "\n",
    "    \"XGBoost\": XGBRegressor(\n",
    "        n_estimators=120,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=1,\n",
    "        verbosity=0\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 6ï¸âƒ£ Cross Validation + Evaluation\n",
    "# =====================================\n",
    "\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    # Sequential CV (no multiprocessing)\n",
    "    cv_r2 = cross_val_score(\n",
    "        pipeline,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=kf,\n",
    "        scoring=\"r2\",\n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    preds = pipeline.predict(X_test)\n",
    "\n",
    "    test_r2 = r2_score(y_test, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"CV_R2_Mean\": cv_r2.mean(),\n",
    "        \"CV_R2_Std\": cv_r2.std(),\n",
    "        \"Test_R2\": test_r2,\n",
    "        \"RMSE\": rmse\n",
    "    })\n",
    "\n",
    "    print(f\"{name} completed.\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 7ï¸âƒ£ Leaderboard\n",
    "# =====================================\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\n",
    "    by=\"CV_R2_Mean\",\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df)\n",
    "\n",
    "best_model = results_df.iloc[0]\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"ðŸ† BEST MODEL\")\n",
    "print(\"==============================\")\n",
    "print(f\"Model Name  : {best_model['Model']}\")\n",
    "print(f\"CV R2 Mean  : {best_model['CV_R2_Mean']:.4f}\")\n",
    "print(f\"Test R2     : {best_model['Test_R2']:.4f}\")\n",
    "print(f\"RMSE        : {best_model['RMSE']:.4f}\")\n",
    "print(\"==============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a334b69e-5ed2-4641-95d3-968e486f9684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters Found:\n",
      "{'model__colsample_bytree': np.float64(0.9464704583099741), 'model__learning_rate': np.float64(0.07011150117432088), 'model__max_depth': 10, 'model__min_child_samples': 12, 'model__n_estimators': 249, 'model__num_leaves': 72, 'model__reg_alpha': np.float64(0.9699098521619943), 'model__reg_lambda': np.float64(0.8324426408004217), 'model__subsample': np.float64(0.6849356442713105)}\n",
      "\n",
      "Tuned Model Performance (Test Set):\n",
      "R2   : 0.9756\n",
      "RMSE : 31.3430\n",
      "\n",
      "Model refitted on full dataset.\n",
      "\n",
      "Final model saved as 'final_lightgbm_sales_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# FINAL LIGHTGBM PIPELINE (NO OUTLIERS REMOVED)\n",
    "# - RandomizedSearchCV\n",
    "# - verbose = -1\n",
    "# - n_jobs = 1\n",
    "# - Final Refit on Full Dataset\n",
    "# ==========================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import randint, uniform\n",
    "import joblib\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 1ï¸âƒ£ Train/Test Split (NO OUTLIER REMOVAL)\n",
    "# =====================================\n",
    "\n",
    "X = df.drop(\"Sales\", axis=1)\n",
    "y = df[\"Sales\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 2ï¸âƒ£ Preprocessing\n",
    "# =====================================\n",
    "\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "categorical_features = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numeric_features),\n",
    "    (\"cat\", categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 3ï¸âƒ£ Base LightGBM Model\n",
    "# =====================================\n",
    "\n",
    "lgbm = LGBMRegressor(\n",
    "    random_state=42,\n",
    "    n_jobs=1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", lgbm)\n",
    "])\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 4ï¸âƒ£ Parameter Distributions\n",
    "# =====================================\n",
    "\n",
    "param_distributions = {\n",
    "    \"model__n_estimators\": randint(100, 400),\n",
    "    \"model__learning_rate\": uniform(0.01, 0.1),\n",
    "    \"model__num_leaves\": randint(20, 100),\n",
    "    \"model__max_depth\": randint(3, 15),\n",
    "    \"model__min_child_samples\": randint(10, 60),\n",
    "    \"model__subsample\": uniform(0.6, 0.4),\n",
    "    \"model__colsample_bytree\": uniform(0.6, 0.4),\n",
    "    \"model__reg_alpha\": uniform(0.0, 1.0),\n",
    "    \"model__reg_lambda\": uniform(0.0, 1.0)\n",
    "}\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 5ï¸âƒ£ Randomized Search\n",
    "# =====================================\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,\n",
    "    cv=3,\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=1,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 6ï¸âƒ£ Best Parameters\n",
    "# =====================================\n",
    "\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 7ï¸âƒ£ Evaluate Tuned Model\n",
    "# =====================================\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "preds = best_model.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, preds)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "print(\"\\nTuned Model Performance (Test Set):\")\n",
    "print(f\"R2   : {r2:.4f}\")\n",
    "print(f\"RMSE : {rmse:.4f}\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 8ï¸âƒ£ Final Refit on FULL DATASET\n",
    "# =====================================\n",
    "\n",
    "best_model.fit(X, y)\n",
    "\n",
    "print(\"\\nModel refitted on full dataset.\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 9ï¸âƒ£ Save Final Model\n",
    "# =====================================\n",
    "\n",
    "joblib.dump(best_model, \"final_lightgbm_sales_model.pkl\")\n",
    "\n",
    "print(\"\\nFinal model saved as 'final_lightgbm_sales_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e2d3d1-a106-49e9-8c5a-8487942a1b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bcc860-63c5-4e1f-ad66-88250f691521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a817493-4be0-4e58-aa3d-2e431bb448d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac40a3f-8939-4bf3-85ab-4bfcb1cfd1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57b2e27-6fb5-425c-924d-d0c55f9cdc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f37b7bb-ed7a-4c1d-ab43-fc811cd33338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a9b26-ad92-439a-bc34-8a4c38bf5521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea54913a-d8e8-415d-b548-36d1bb105c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1002199f-1a5a-4195-9886-ee378e6e048b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15fb9b-a7b2-4c97-b03c-74bbb55b6203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef553b-6b1e-4726-a4f6-5a64f25a6bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd497e4f-fb0e-4320-876d-92c13ea1eae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009458f4-f124-40ed-b437-2712b89c38c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
